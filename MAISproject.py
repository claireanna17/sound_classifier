# -*- coding: utf-8 -*-
"""MAISproject(1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-BmeVv17cvLMfoz76Yq6J0gC2B3uy3z1

## **Import necessary libraries**
"""

import torch
from torch.utils.data import Dataset, DataLoader
import torch.nn as nn
import torch.optim as optim
import torch.nn.functional as F
import torchvision
from torchvision.models import efficientnet_b0, EfficientNet_B0_Weights
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import librosa
import cv2
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, precision_score, recall_score, confusion_matrix
import os

"""## **Load data**"""

path='C:/Users/ASUS/Downloads/FSDKaggle2018/'

# Read metadata file
metadata_file = path + 'FSDKaggle2018.meta/train_post_competition.csv'
# print(metadata_file)
# contents = os.listdir('/content/drive/MyDrive/FSDKaggle2018')

# for item in contents:
#     print(item)
train = pd.read_csv(metadata_file)

# Take relevant columns (features, labels)
train = train[['fname', 'freesound_id', 'label']]
print(train)

# Audio training data path
data_path = path + 'FSDKaggle2018l.audio_train/'

IMG_SIZE = (128, 128)
TRAIN_PATH = path + 'FSDKaggle2018.audio_train/'
TEST_PATH = path + 'FSDKaggle2018.audio_test/'
batch_size = 64

"""## **Load datasets**

#### Create custom dataset class
"""

class SoundDataset(Dataset):
    def __init__(self, dataframe, path, test=False):
        super(SoundDataset, self).__init__()
        self.dataframe = dataframe
        self.path = path
        self.test = test

    def __len__(self):
        return len(self.dataframe)

    def __getitem__(self, idx):
        file_path = self.dataframe.fname.values[idx]
        label = self.dataframe.label.values[idx]
        path = (TEST_PATH if self.test else TRAIN_PATH) + file_path
        signal, _ = librosa.load(path)
        signal = librosa.feature.melspectrogram(y=signal)
        signal = librosa.power_to_db(signal, ref=np.max)

        try:
            resized = cv2.resize(signal, (IMG_SIZE[1], IMG_SIZE[0]))
        except Exception as e:
            print(path)
            print(str(e))
            resized = np.zeros(shape=(IMG_SIZE[1], IMG_SIZE[0]))

        X = np.stack([resized] * 3)
        X = torch.tensor(X, dtype=torch.float32)

        if not self.test:
            y = label_encoder[label]
            return X, y
        else:
            return X

"""#### Divide data into datasets"""

x_train, x_validation, y_train, y_validation = train_test_split(train, train, test_size=0.2, shuffle=True, random_state=5)
train_dataset = SoundDataset(x_train, TRAIN_PATH)
val_dataset = SoundDataset(x_validation, TRAIN_PATH)
train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)

print(x_train.head(), x_train.shape)
print(y_train.head(), y_train.shape)

labels = np.unique(train.label.values)
label_encoder = {label:i for i, label in enumerate(labels)}

"""## **Build model**

bug fix
"""

from torchvision.models._api import WeightsEnum
from torch.hub import load_state_dict_from_url

def get_state_dict(self, *args, **kwargs):
    kwargs.pop("check_hash")
    return load_state_dict_from_url(self.url, *args, **kwargs)
WeightsEnum.get_state_dict = get_state_dict

"""Model structure"""

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device)
weights = EfficientNet_B0_Weights.IMAGENET1K_V1
print(weights)
model = efficientnet_b0(weights=weights)
model.classifier[1] = torch.nn.Linear(1280, 41)
model.to(device)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
print(optimizer)
cost = torch.nn.CrossEntropyLoss()
print(cost)

"""## **Train model**

#### Training loop
"""

# Initialize lists to store training history
train_losses = []
train_accuracies = []
val_losses = []
val_accuracies = []
def training(epochs):
    for epoch in range(epochs):
        model.train()
        train_loss = 0
        train_correct = 0
        for X, y in train_loader:
            X, y = X.to(device), y.to(device)
            optimizer.zero_grad()
            pred = model(X)
            loss = cost(pred, y)
            loss.backward()
            optimizer.step()
            train_loss += loss.item() * X.size(0)
            train_correct += torch.sum(pred.argmax(1) == y).item()

        train_loss = train_loss / len(train_loader.dataset)
        train_accuracy = train_correct / len(train_loader.dataset)

        model.eval()
        val_loss = 0
        val_correct = 0
        with torch.no_grad():
            for X, y in val_loader:
                X, y = X.to(device), y.to(device)
                pred = model(X)
                loss = cost(pred, y)
                val_loss += loss.item() * X.size(0)
                val_correct += torch.sum(pred.argmax(1) == y).item()

        val_loss = val_loss / len(val_loader.dataset)
        val_accuracy = val_correct / len(val_loader.dataset)

        print("Epoch {}, Train Loss: {:.4f}, Train Accuracy: {:.4f}, Val Loss: {:.4f}, Val Accuracy: {:.4f}".format(epoch+1, train_loss, train_accuracy, val_loss, val_accuracy))
        train_losses.append(train_loss)
        train_accuracies.append(train_accuracy)
        val_losses.append(val_loss)
        val_accuracies.append(val_accuracy)

"""#### Train for a number of epochs"""

num_epochs = 12
training(num_epochs)

"""#### Plot results"""

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(train_losses, label='Training Loss')
plt.plot(val_losses, label='Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()
plt.title('Training and Validation Loss')

plt.subplot(1, 2, 2)
plt.plot(train_accuracies, label='Training Accuracy')
plt.plot(val_accuracies, label='Validation Accuracy')
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.legend()
plt.title('Training and Validation Accuracy')

plt.show()

"""## **Evaluate model**

#### Take the testing dataset
"""

testmetadata_file = path + 'FSDKaggle2018.meta/test_post_competition_scoring_clips.csv'
test = pd.read_csv(testmetadata_file)
# Take relevant columns (features, labels)
test = test[['fname', 'freesound_id', 'label']]
print(test)

# Audio training data path
test_data_path = path + 'FSDKaggle2018l.audio_test/'

test_dataset = SoundDataset(test, TEST_PATH, test=True)
test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)
predictions = torch.tensor([])

"""#### Make predictions"""

model.eval()
with torch.no_grad():
    for X in test_loader:
        X = X.to(device)
        y_hat = model(X)
        predictions = torch.cat([predictions, y_hat.cpu()])

predictions = F.softmax(predictions, dim=1).detach().numpy()

result = test.copy()

for i in range(len(test)):
    p = predictions[i, :]
    idx = np.argmax(p)
    result.label[i] = labels[idx]

result.to_csv('results.csv', index=False, header=True)

result.head()

"""#### Evaluate metrics"""

true_labels = test.label.values
pred_labels = result.label.values

test_label_encoder = LabelEncoder()

# Calculate accuracy
accuracy = accuracy_score(true_labels, pred_labels)
print(f"Accuracy: {accuracy}")

# Calculate precision and recall
precision = precision_score(true_labels, pred_labels, average='weighted')
recall = recall_score(true_labels, pred_labels, average='weighted')
print(f"Precision: {precision}")
print(f"Recall: {recall}")

# Calculate the confusion matrix
conf_matrix = confusion_matrix(true_labels, pred_labels)
print("Confusion Matrix:")
print(conf_matrix)

# Calculate the loss score
# Create a label encoder to convert text labels to integers
test_label_encoder = LabelEncoder()
enc_true_labels = test_label_encoder.fit_transform(true_labels)
loss = nn.CrossEntropyLoss()
loss_value = loss(torch.tensor(predictions), torch.tensor(enc_true_labels, dtype=torch.long))
print(f"Logistic Loss: {loss_value.item()}")

"""## **Save and load model**"""

model

"""#### Save"""

# Save the entire model, including the state_dict, optimizer state, and other information
torch.save({
    'epoch': num_epochs,
    'model_state_dict': model.state_dict(),
    'optimizer_state_dict': optimizer.state_dict(),
    'loss': cost,
}, 'modelV1.2.pth')

"""#### Load"""

# Load the model
checkpoint = torch.load('modelV1.2.pth')
model.load_state_dict(checkpoint['model_state_dict'])
optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
epoch = checkpoint['epoch']
loss = checkpoint['loss']

model
